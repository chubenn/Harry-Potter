IDE      := a * b
total    := c + a * b
'
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 100)
summary(fit, ci = TRUE, standardized = TRUE)
pacman::p_load(tidyverse,lavaan,car)
options(contrasts=c("contr.helmert",  "contr.poly"))
model4 <- function(iv, dv, med, data, samples=5000) {
model <- paste0(med, " ~ a*", iv, "
", dv, " ~ b*", med, " + cp*", iv, "
ind := a*b
c := cp + a*b")
set.seed(1839)
out <- lavaan::parameterEstimates(
lavaan::sem(model=model, data=data, se="boot", bootstrap=samples),
boot.ci.type="bca.simple")
out[7,c(6:8)] <- NA
out <- out[c(1,2,3,7,8),c(4:10)]
rownames(out) <- 1:nrow(out)
return(out)
}
unslang <- read_csv("C:/Users/Branly Mclanbry/Desktop/slang.csv") %>%
janitor::clean_names()
slang <- unslang %>%
filter(progress == 100,
believable > 2,
usedate != 2) %>%
mutate(
dv_conf     = (slangconf1 + slangconf2)/2,
dv_ent      = (entitdv_entitdv_1 + entitdv_entitdv_2 + entitdv_entitdv_3 + entitdv_entitdv_4 +
entitdv_entitdv_5 + entitdv_entitdv_6 + entitdv_entitdv_7 + entitdv_entitdv_8 +
entitdv_entitdv_9)/9,
dv_proto    = (protodv_protodv_1 + protodv_protodv_2 + protodv_protodv_3 + protodv_protodv_4 +
protodv_protodv_5)/5,
dv_hsuid    = (hsuiddv_hsuiddv_1 + hsuiddv_hsuiddv_2 + hsuiddv_hsuiddv_3 + hsuiddv_hsuiddv_4 +
hsuiddv_hsuiddv_5 + hsuiddv_hsuiddv_6 + hsuiddv_hsuiddv_7 + hsuiddv_hsuiddv_8 +
hsuiddv_hsuiddv_9)/9,
dv_unc      = (uncdv_uncdv_1 + uncdv_uncdv_2 + uncdv_uncdv_3 + uncdv_uncdv_4 +
uncdv_uncdv_5)/5,
dv_ost      = (ostdv_ostdv_1 + ostdv_ostdv_2 + ostdv_ostdv_3 + ostdv_ostdv_4 + ostdv_ostdv_5 +
ostdv_ostdv_6 + ostdv_ostdv_7 + ostdv_ostdv_8 + ostdv_ostdv_9 +
ostdv_ostdv_10)/10,
dv_self     = (selfesteem_uncdv_1 + selfesteem_uncdv_2 + selfesteem_uncdv_3 + selfesteem_uncdv_4 +
selfesteem_uncdv_5 + selfesteem_uncdv_6 + selfesteem_uncdv_7 + selfesteem_uncdv_8 +
selfesteem_uncdv_9 + selfesteem_uncdv_10)/10,
iv_uncercat = (ifelse(is.na(unclow_1), 'high', 'low')),
iv_uncernum = (ifelse(is.na(unclow_1), 1, 0)),
iv_bfcat       =  case_when(bflow_3 > 11 ~ "low",
bfhigh_1 > 11 ~ "high",
is.na(bflow_3) | is.na(bfhigh_1) ~ "control"),
iv_bfnum       =  case_when(bflow_3 > 11 ~ 1,
bfhigh_1 > 11 ~ 2,
is.na(bflow_3) | is.na(bfhigh_1) ~ 3),
iv_bfcat.2       =  case_when(bflow_3 > 11 ~ "low",
bfhigh_1 > 11 ~ "high",
is.na(bflow_3) | is.na(bfhigh_1) ~ "low"),
iv_bfnum.2       =  case_when(bflow_3 > 11 ~ 1,
bfhigh_1 > 11 ~ 2,
is.na(bflow_3) | is.na(bfhigh_1) ~ 1),
iv_gender      =  gender,
iv_class       =  classstand,
iv_lang        =  nation,
iv_eth         =  ethnicity,
iv_age         =  as.numeric(age_4),
dv_power_iq = (ostdv_ostdv_9 + ostdv_ostdv_10+ ostdv_ostdv_11)/3,
dv_alone = (ostdv_ostdv_1 + ostdv_ostdv_2 + ostdv_ostdv_3 + ostdv_ostdv_6 +
ostdv_ostdv_7 + ostdv_ostdv_8)/6)
mediation <- '
dv_power_iq ~ c * iv_bfnum.2
dv_conf ~ a * iv_bfnum.2
dv_power_iq ~ b * dv_conf
IDE      := a * b
total    := c + a * b
'
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
model4(dv_power_iq, iv_bfnum.2, dv_conf, slang)
cor.test(slang_bf$ostdv_ostdv_10, slang_bf$ostdv_ostdv_9)
analysis <- lm(dv_power~
iv_bfnum.2 + dv_conf, data = slang)
summary(analysis, type = "III")
tapply(slang_bf$dv_conf, list(slang_bf$iv_uncercat,slang_bf$iv_bfcat),mean)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
mediation <- '
dv_power_iq ~ c * iv_bfnum.2
dv_conf ~ a * iv_bfnum.2
dv_power_iq ~ b * dv_conf
IDE      := a * b
total    := c + a * b
'
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
??describe
desctools::describe(slang$iv_gender)
DescTools::describe(slang$iv_gender)
psych::describe(slang$iv_gender)
psych::describe(slang$iv_eth)
table(slang$iv_gender)
table(slang$iv_eth)
table(slang$iv_gender)
147/43+147+5
147/(43+147+5)
81/(81+4+12+1+75+1+21)
psych::describe(slang$iv_age)
pacman::p_load(tidyverse,lavaan,car, psych)
conf <- slang %>% select(ostdv_ostdv_9 , ostdv_ostdv_10 , ostdv_ostdv_11)
View(conf)
conf1 <- slang %>% select(slangconf1 , slangconf2)
conf <- slang %>% select(ostdv_ostdv_9 , ostdv_ostdv_10 , ostdv_ostdv_11) %>%
alpha()
alpha(conf)
conf1 <- slang %>% select(slangconf1 , slangconf2)
conf <- slang %>% select(ostdv_ostdv_9 , ostdv_ostdv_10 , ostdv_ostdv_11)
alpha(conf)
alpha(conf)
conf <- slang %>% select(ostdv_ostdv_9 , ostdv_ostdv_11)
alpha(conf)
conf <- slang %>% select(ostdv_ostdv_4, ostdv_ostdv_9 , ostdv_ostdv_10 , ostdv_ostdv_11)
alpha(conf)
slang <- unslang %>%
filter(progress == 100,
believable > 2,
usedate != 2) %>%
mutate(
dv_conf     = (slangconf1 + slangconf2)/2,
dv_ent      = (entitdv_entitdv_1 + entitdv_entitdv_2 + entitdv_entitdv_3 + entitdv_entitdv_4 +
entitdv_entitdv_5 + entitdv_entitdv_6 + entitdv_entitdv_7 + entitdv_entitdv_8 +
entitdv_entitdv_9)/9,
dv_proto    = (protodv_protodv_1 + protodv_protodv_2 + protodv_protodv_3 + protodv_protodv_4 +
protodv_protodv_5)/5,
dv_hsuid    = (hsuiddv_hsuiddv_1 + hsuiddv_hsuiddv_2 + hsuiddv_hsuiddv_3 + hsuiddv_hsuiddv_4 +
hsuiddv_hsuiddv_5 + hsuiddv_hsuiddv_6 + hsuiddv_hsuiddv_7 + hsuiddv_hsuiddv_8 +
hsuiddv_hsuiddv_9)/9,
dv_unc      = (uncdv_uncdv_1 + uncdv_uncdv_2 + uncdv_uncdv_3 + uncdv_uncdv_4 +
uncdv_uncdv_5)/5,
dv_ost      = (ostdv_ostdv_1 + ostdv_ostdv_2 + ostdv_ostdv_3 + ostdv_ostdv_4 + ostdv_ostdv_5 +
ostdv_ostdv_6 + ostdv_ostdv_7 + ostdv_ostdv_8 + ostdv_ostdv_9 +
ostdv_ostdv_10)/10,
dv_self     = (selfesteem_uncdv_1 + selfesteem_uncdv_2 + selfesteem_uncdv_3 + selfesteem_uncdv_4 +
selfesteem_uncdv_5 + selfesteem_uncdv_6 + selfesteem_uncdv_7 + selfesteem_uncdv_8 +
selfesteem_uncdv_9 + selfesteem_uncdv_10)/10,
iv_uncercat = (ifelse(is.na(unclow_1), 'high', 'low')),
iv_uncernum = (ifelse(is.na(unclow_1), 1, 0)),
iv_bfcat       =  case_when(bflow_3 > 11 ~ "low",
bfhigh_1 > 11 ~ "high",
is.na(bflow_3) | is.na(bfhigh_1) ~ "control"),
iv_bfnum       =  case_when(bflow_3 > 11 ~ 1,
bfhigh_1 > 11 ~ 2,
is.na(bflow_3) | is.na(bfhigh_1) ~ 3),
iv_bfcat.2       =  case_when(bflow_3 > 11 ~ "low",
bfhigh_1 > 11 ~ "high",
is.na(bflow_3) | is.na(bfhigh_1) ~ "low"),
iv_bfnum.2       =  case_when(bflow_3 > 11 ~ 1,
bfhigh_1 > 11 ~ 2,
is.na(bflow_3) | is.na(bfhigh_1) ~ 1),
iv_gender      =  gender,
iv_class       =  classstand,
iv_lang        =  nation,
iv_eth         =  ethnicity,
iv_age         =  as.numeric(age_4),
dv_power_iq = (ostdv_ostdv_4, ostdv_ostdv_9 + ostdv_ostdv_10+ ostdv_ostdv_11)/3,
dv_alone = (ostdv_ostdv_1 + ostdv_ostdv_2 + ostdv_ostdv_3 + ostdv_ostdv_6 +
ostdv_ostdv_7 + ostdv_ostdv_8)/6)
mediation <- '
dv_power_iq ~ c * iv_bfnum.2
dv_conf ~ a * iv_bfnum.2
dv_power_iq ~ b * dv_conf
IDE      := a * b
total    := c + a * b
'
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
slang <- unslang %>%
filter(progress == 100,
believable > 2,
usedate != 2) %>%
mutate(
dv_conf     = (slangconf1 + slangconf2)/2,
dv_ent      = (entitdv_entitdv_1 + entitdv_entitdv_2 + entitdv_entitdv_3 + entitdv_entitdv_4 +
entitdv_entitdv_5 + entitdv_entitdv_6 + entitdv_entitdv_7 + entitdv_entitdv_8 +
entitdv_entitdv_9)/9,
dv_proto    = (protodv_protodv_1 + protodv_protodv_2 + protodv_protodv_3 + protodv_protodv_4 +
protodv_protodv_5)/5,
dv_hsuid    = (hsuiddv_hsuiddv_1 + hsuiddv_hsuiddv_2 + hsuiddv_hsuiddv_3 + hsuiddv_hsuiddv_4 +
hsuiddv_hsuiddv_5 + hsuiddv_hsuiddv_6 + hsuiddv_hsuiddv_7 + hsuiddv_hsuiddv_8 +
hsuiddv_hsuiddv_9)/9,
dv_unc      = (uncdv_uncdv_1 + uncdv_uncdv_2 + uncdv_uncdv_3 + uncdv_uncdv_4 +
uncdv_uncdv_5)/5,
dv_ost      = (ostdv_ostdv_1 + ostdv_ostdv_2 + ostdv_ostdv_3 + ostdv_ostdv_4 + ostdv_ostdv_5 +
ostdv_ostdv_6 + ostdv_ostdv_7 + ostdv_ostdv_8 + ostdv_ostdv_9 +
ostdv_ostdv_10)/10,
dv_self     = (selfesteem_uncdv_1 + selfesteem_uncdv_2 + selfesteem_uncdv_3 + selfesteem_uncdv_4 +
selfesteem_uncdv_5 + selfesteem_uncdv_6 + selfesteem_uncdv_7 + selfesteem_uncdv_8 +
selfesteem_uncdv_9 + selfesteem_uncdv_10)/10,
iv_uncercat = (ifelse(is.na(unclow_1), 'high', 'low')),
iv_uncernum = (ifelse(is.na(unclow_1), 1, 0)),
iv_bfcat       =  case_when(bflow_3 > 11 ~ "low",
bfhigh_1 > 11 ~ "high",
is.na(bflow_3) | is.na(bfhigh_1) ~ "control"),
iv_bfnum       =  case_when(bflow_3 > 11 ~ 1,
bfhigh_1 > 11 ~ 2,
is.na(bflow_3) | is.na(bfhigh_1) ~ 3),
iv_bfcat.2       =  case_when(bflow_3 > 11 ~ "low",
bfhigh_1 > 11 ~ "high",
is.na(bflow_3) | is.na(bfhigh_1) ~ "low"),
iv_bfnum.2       =  case_when(bflow_3 > 11 ~ 1,
bfhigh_1 > 11 ~ 2,
is.na(bflow_3) | is.na(bfhigh_1) ~ 1),
iv_gender      =  gender,
iv_class       =  classstand,
iv_lang        =  nation,
iv_eth         =  ethnicity,
iv_age         =  as.numeric(age_4),
dv_power_iq = (ostdv_ostdv_4 + ostdv_ostdv_9 + ostdv_ostdv_10+ ostdv_ostdv_11)/4,
dv_alone = (ostdv_ostdv_1 + ostdv_ostdv_2 + ostdv_ostdv_3 + ostdv_ostdv_6 +
ostdv_ostdv_7 + ostdv_ostdv_8)/6)
mediation <- '
dv_power_iq ~ c * iv_bfnum.2
dv_conf ~ a * iv_bfnum.2
dv_power_iq ~ b * dv_conf
IDE      := a * b
total    := c + a * b
'
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
alpha(conf)
conf1 <- slang %>% select(slangconf1 , slangconf2)
alpha(conf1)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 5000, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 5000, ci = TRUE, standardized = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 1000, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
??Boot
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 1000, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 1000, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 500, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 100, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
fit <- sem(mediation, data = slang, se = "bootstrap", bootstrap = 1000, ci = TRUE, standardized = TRUE)
summary(fit, ci = TRUE, estimates = TRUE)
pacman::p_load(tidytext,janitor,quanteda,tidyverse)
library(quanteda.dictionaries)
library(psych)
library(GPArotation)
library(MASS)
library(harrypotter)
BeginningColumn <- 6
DF <- read_csv("GitHub/Harry Potter/2018-06-25 - MEH/2018-06-25_-_MEH-Output_Verbose-1.csv")
DF[BeginningColumn:length(DF)] <- apply(DF[BeginningColumn:length(DF)], 2, as.character)
DF[BeginningColumn:length(DF)] <- apply(DF[BeginningColumn:length(DF)], 2, as.numeric)
DF <- subset(DF, WordCount >= 5000)
DF <- subset(DF, WordCount >= 8000)
kmo = function( data ){
X <- cor(as.matrix(data))
iX <- ginv(X)
S2 <- diag(diag((iX^-1)))
AIS <- S2%*%iX%*%S2                      # anti-image covariance matrix
IS <- X+AIS-2*S2                         # image covariance matrix
Dai <- sqrt(diag(diag(AIS)))
IR <- ginv(Dai)%*%IS%*%ginv(Dai)         # image correlation matrix
AIR <- ginv(Dai)%*%AIS%*%ginv(Dai)       # anti-image correlation matrix
a <- apply((AIR - diag(diag(AIR)))^2, 2, sum)
AA <- sum(a)
b <- apply((X - diag(nrow(X)))^2, 2, sum)
BB <- sum(b)
MSA <- b/(b+a)                        # indiv. measures of sampling adequacy
AIR <- AIR-diag(nrow(AIR))+diag(MSA)  # Examine the anti-image of the correlation matrix. That is the  negative of the partial correlations, partialling out all other variables.
kmo <- BB/(AA+BB)                     # overall KMO statistic
# Reporting the conclusion
if (kmo >= 0.00 && kmo < 0.50){test <- 'The KMO test yields a POOR degree of common variance.'}
else if (kmo >= 0.50 && kmo < 0.60){test <- 'The KMO test yields a SOMEWHAT POOR degree of common variance.'}
else if (kmo >= 0.60 && kmo < 0.70){test <- 'The KMO test yields a DECENT degree of common variance.'}
else if (kmo >= 0.70 && kmo < 0.80){test <- 'The KMO test yields a GOOD degree of common variance.' }
else if (kmo >= 0.80 && kmo < 0.90){test <- 'The KMO test yields a VERY GOOD degree of common variance.' }
else { test <- 'The KMO test yields a FANTASTIC degree of common variance.' }
ans <- list( overall = kmo,
report = test,
individual = MSA,
AIS = AIS,
AIR = AIR )
return(ans)
}
Bartlett.sphericity.test <- function(x)
{
method <- "Bartlett's test of sphericity"
data.name <- deparse(substitute(x))
x <- subset(x, complete.cases(x))
n <- nrow(x)
p <- ncol(x)
chisq <- (1-n+(2*p+5)/6)*log(det(cor(x)))
df <- p*(p-1)/2
p.value <- pchisq(chisq, df, lower.tail=FALSE)
names(chisq) <- "X-squared"
names(df) <- "df"
return(structure(list(statistic=chisq, parameter=df, p.value=p.value, method=method, data.name=data.name), class="htest"))
}
PCAFunction <- function(InputData, NumberOfFactors) {
#gets our scree plot (uncomment next line to get the plot)
#fa.parallel(InputData, fa="PC", main="Scree Plot")
options(width=10000)
options(max.print=2000000000)
#runs the KMO test and prints our results
cat("\n\nKMO_TEST:\n\n")
KMO_Results <- kmo(InputData)
cat(paste("KMO_METRIC: ", KMO_Results$overall, "\n", KMO_Results$report, sep=""))
#same for the Bartlett test of sphericity
cat("\n\nBARTLETT_SPHERICITY_TEST:\n\n")
print(Bartlett.sphericity.test(InputData))
#runs the PCA and prints the results
cat("\n\nFACTOR_ANALYSIS_RESULTS:\n\n")
PCA <- principal(InputData, nfactors=NumberOfFactors, residuals=FALSE, rotate="varimax", method="regression")
print(PCA)
return(PCA)
}
setwd("C:/Users/Branly Mclanbry/Documents/GitHub/Harry Potter")
dir.create("Results", showWarnings = FALSE)
sink(paste("Results/", Sys.Date(), "_-_PCA_Results.txt", sep=""))
PCA_Results = PCAFunction(InputData = DF[BeginningColumn:length(DF)],
NumberOfFactors=7)
PCA_Results = PCAFunction(InputData = DF[BeginningColumn:length(DF)],
NumberOfFactors=7)
BeginningColumn <- 7
DF <- read_csv("GitHub/Harry Potter/2018-06-25 - MEH/2018-06-25_-_MEH-Output_Verbose-1.csv")
DF[BeginningColumn:length(DF)] <- apply(DF[BeginningColumn:length(DF)], 2, as.character)
DF[BeginningColumn:length(DF)] <- apply(DF[BeginningColumn:length(DF)], 2, as.numeric)
DF <- read_csv("GitHub/Harry Potter/2018-06-25 - MEH/2018-06-25_-_MEH-Output_Verbose-1.csv")
DF <- read_csv("GitHub/Harry Potter/2018-06-25 - MEH/2018-06-25_-_MEH-Output_Verbose-1.csv")
DF <- subset(DF, WordCount >= 8000)
kmo = function( data ){
X <- cor(as.matrix(data))
iX <- ginv(X)
S2 <- diag(diag((iX^-1)))
AIS <- S2%*%iX%*%S2                      # anti-image covariance matrix
IS <- X+AIS-2*S2                         # image covariance matrix
Dai <- sqrt(diag(diag(AIS)))
IR <- ginv(Dai)%*%IS%*%ginv(Dai)         # image correlation matrix
AIR <- ginv(Dai)%*%AIS%*%ginv(Dai)       # anti-image correlation matrix
a <- apply((AIR - diag(diag(AIR)))^2, 2, sum)
AA <- sum(a)
b <- apply((X - diag(nrow(X)))^2, 2, sum)
BB <- sum(b)
MSA <- b/(b+a)                        # indiv. measures of sampling adequacy
AIR <- AIR-diag(nrow(AIR))+diag(MSA)  # Examine the anti-image of the correlation matrix. That is the  negative of the partial correlations, partialling out all other variables.
kmo <- BB/(AA+BB)                     # overall KMO statistic
# Reporting the conclusion
if (kmo >= 0.00 && kmo < 0.50){test <- 'The KMO test yields a POOR degree of common variance.'}
else if (kmo >= 0.50 && kmo < 0.60){test <- 'The KMO test yields a SOMEWHAT POOR degree of common variance.'}
else if (kmo >= 0.60 && kmo < 0.70){test <- 'The KMO test yields a DECENT degree of common variance.'}
else if (kmo >= 0.70 && kmo < 0.80){test <- 'The KMO test yields a GOOD degree of common variance.' }
else if (kmo >= 0.80 && kmo < 0.90){test <- 'The KMO test yields a VERY GOOD degree of common variance.' }
else { test <- 'The KMO test yields a FANTASTIC degree of common variance.' }
ans <- list( overall = kmo,
report = test,
individual = MSA,
AIS = AIS,
AIR = AIR )
return(ans)
}
Bartlett.sphericity.test <- function(x)
{
method <- "Bartlett's test of sphericity"
data.name <- deparse(substitute(x))
x <- subset(x, complete.cases(x))
n <- nrow(x)
p <- ncol(x)
chisq <- (1-n+(2*p+5)/6)*log(det(cor(x)))
df <- p*(p-1)/2
p.value <- pchisq(chisq, df, lower.tail=FALSE)
names(chisq) <- "X-squared"
names(df) <- "df"
return(structure(list(statistic=chisq, parameter=df, p.value=p.value, method=method, data.name=data.name), class="htest"))
}
PCAFunction <- function(InputData, NumberOfFactors) {
#gets our scree plot (uncomment next line to get the plot)
#fa.parallel(InputData, fa="PC", main="Scree Plot")
options(width=10000)
options(max.print=2000000000)
#runs the KMO test and prints our results
cat("\n\nKMO_TEST:\n\n")
KMO_Results <- kmo(InputData)
cat(paste("KMO_METRIC: ", KMO_Results$overall, "\n", KMO_Results$report, sep=""))
#same for the Bartlett test of sphericity
cat("\n\nBARTLETT_SPHERICITY_TEST:\n\n")
print(Bartlett.sphericity.test(InputData))
#runs the PCA and prints the results
cat("\n\nFACTOR_ANALYSIS_RESULTS:\n\n")
PCA <- principal(InputData, nfactors=NumberOfFactors, residuals=FALSE, rotate="varimax", method="regression")
print(PCA)
return(PCA)
}
setwd("C:/Users/Branly Mclanbry/Documents/GitHub/Harry Potter")
dir.create("Results", showWarnings = FALSE)
sink(paste("Results/", Sys.Date(), "_-_PCA_Results.txt", sep=""))
PCA_Results = PCAFunction(InputData = DF[BeginningColumn:length(DF)],
NumberOfFactors=7)
DF <- read_csv("GitHub/Harry Potter/2018-06-25 - MEH/2018-06-25_-_MEH-OutputBinary-1.csv")
DF <- read.csv("2018-06-25 - MEH/2018-06-25_-_MEH-Output_Binary-1.csv")
DF[BeginningColumn:length(DF)] <- apply(DF[BeginningColumn:length(DF)], 2, as.character)
DF[BeginningColumn:length(DF)] <- apply(DF[BeginningColumn:length(DF)], 2, as.numeric)
DF <- subset(DF, WordCount >= 8000)
kmo = function( data ){
X <- cor(as.matrix(data))
iX <- ginv(X)
S2 <- diag(diag((iX^-1)))
AIS <- S2%*%iX%*%S2                      # anti-image covariance matrix
IS <- X+AIS-2*S2                         # image covariance matrix
Dai <- sqrt(diag(diag(AIS)))
IR <- ginv(Dai)%*%IS%*%ginv(Dai)         # image correlation matrix
AIR <- ginv(Dai)%*%AIS%*%ginv(Dai)       # anti-image correlation matrix
a <- apply((AIR - diag(diag(AIR)))^2, 2, sum)
AA <- sum(a)
b <- apply((X - diag(nrow(X)))^2, 2, sum)
BB <- sum(b)
MSA <- b/(b+a)                        # indiv. measures of sampling adequacy
AIR <- AIR-diag(nrow(AIR))+diag(MSA)  # Examine the anti-image of the correlation matrix. That is the  negative of the partial correlations, partialling out all other variables.
kmo <- BB/(AA+BB)                     # overall KMO statistic
# Reporting the conclusion
if (kmo >= 0.00 && kmo < 0.50){test <- 'The KMO test yields a POOR degree of common variance.'}
else if (kmo >= 0.50 && kmo < 0.60){test <- 'The KMO test yields a SOMEWHAT POOR degree of common variance.'}
else if (kmo >= 0.60 && kmo < 0.70){test <- 'The KMO test yields a DECENT degree of common variance.'}
else if (kmo >= 0.70 && kmo < 0.80){test <- 'The KMO test yields a GOOD degree of common variance.' }
else if (kmo >= 0.80 && kmo < 0.90){test <- 'The KMO test yields a VERY GOOD degree of common variance.' }
else { test <- 'The KMO test yields a FANTASTIC degree of common variance.' }
ans <- list( overall = kmo,
report = test,
individual = MSA,
AIS = AIS,
AIR = AIR )
return(ans)
}
Bartlett.sphericity.test <- function(x)
{
method <- "Bartlett's test of sphericity"
data.name <- deparse(substitute(x))
x <- subset(x, complete.cases(x))
n <- nrow(x)
p <- ncol(x)
chisq <- (1-n+(2*p+5)/6)*log(det(cor(x)))
df <- p*(p-1)/2
p.value <- pchisq(chisq, df, lower.tail=FALSE)
names(chisq) <- "X-squared"
names(df) <- "df"
return(structure(list(statistic=chisq, parameter=df, p.value=p.value, method=method, data.name=data.name), class="htest"))
}
PCAFunction <- function(InputData, NumberOfFactors) {
#gets our scree plot (uncomment next line to get the plot)
#fa.parallel(InputData, fa="PC", main="Scree Plot")
options(width=10000)
options(max.print=2000000000)
#runs the KMO test and prints our results
cat("\n\nKMO_TEST:\n\n")
KMO_Results <- kmo(InputData)
cat(paste("KMO_METRIC: ", KMO_Results$overall, "\n", KMO_Results$report, sep=""))
#same for the Bartlett test of sphericity
cat("\n\nBARTLETT_SPHERICITY_TEST:\n\n")
print(Bartlett.sphericity.test(InputData))
#runs the PCA and prints the results
cat("\n\nFACTOR_ANALYSIS_RESULTS:\n\n")
PCA <- principal(InputData, nfactors=NumberOfFactors, residuals=FALSE, rotate="varimax", method="regression")
print(PCA)
return(PCA)
}
setwd("C:/Users/Branly Mclanbry/Documents/GitHub/Harry Potter")
dir.create("Results", showWarnings = FALSE)
sink(paste("Results/", Sys.Date(), "_-_PCA_Results.txt", sep=""))
PCA_Results = PCAFunction(InputData = DF[BeginningColumn:length(DF)],
NumberOfFactors=7)
devtools::install_github("bradleyboehmke/harrypotter")
pacman::p_load(tidytext,janitor,quanteda,tidyverse)
devtools::install_github("kbenoit/quanteda.dictionaries")
library(quanteda.dictionaries)
library(psych)
library(GPArotation)
library(MASS)
library(harrypotter)
options(max.print = 500)
stop <- rbind(tibble(text = stopwords(source = "smart")),"ill","im","yeah","dont","hey","back","lets")
titles <- c("Philosopher's Stone", "Chamber of Secrets", "Prisoner of Azkaban",
"Goblet of Fire", "Order of the Phoenix", "Half-Blood Prince",
"Deathly Hallows")
book_list <- list(philosophers_stone, chamber_of_secrets, prisoner_of_azkaban,
goblet_of_fire, order_of_the_phoenix, half_blood_prince,
deathly_hallows)
books <- list(
philosophers_stone,
chamber_of_secrets,
prisoner_of_azkaban,
goblet_of_fire,
order_of_the_phoenix,
half_blood_prince,
deathly_hallows) %>%
set_names(titles) %>%
map_df(as.tibble, .id = "book_list") %>%
mutate(linenumber = row_number(),
book_factor = factor(book_list))
books <- books %>%
group_by(book_factor) %>%
mutate(chapter = row_number()) %>%
filter(!is.na(value))
write.csv(books,"harrypottwer.csv")
liwc_book <- liwcalike(books$value, dictionary = data_dictionary_NRC) %>%
mutate(linenumber = row_number())
full_liwc <- inner_join(books, liwc_book)
View(full_liwc)
